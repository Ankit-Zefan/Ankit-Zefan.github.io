---
---

@inproceedings{shen2023mostgan,
  author    = {Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  title     = {MoStGAN: Video Generation with Temporal Motion Style},
  group          = {Mohamed Elhoseiny},
  org            = {Vision-CAIR  KAUST},
  year           = {2023},
  place          = {Jedda Saudi Arabia},
  img  = {assets/img/publications/mostgan.png},
  info = {We argue that a single time-agnostic latent vector of style-based generator is insufficient to model various motions and hence introduce additional time-dependent motion styles to model diverse motion patterns. In addition, a Motion Style Attention modulation mechanism is proposed to augment frames with vivid dynamics.},
}

@InProceedings{shenKaustdial,
  title          = {Affective Visual Dialog},
  group          = {Mohamed Elhoseiny},
  org            = {Vision-CAIR  KAUST},
  year           = {2022},
  place          = {Jedda Saudi Arabia},
  img            = {assets/img/projects/dial.png},
  info           = {We study the role of affective language in the form of conversation grounded on visual stimuli in informing human emotion and collect a new dataset for (1) Dialog-based Question Answering; (2) Dialog-based Emotion classification and Affective explanation.}
}

@InProceedings{shenkaustinr,
  title          = {Adversarial Text to Continuous Image Generation},
  group          = {Mohamed Elhoseiny},
  org            = {Vision-CAIR  KAUST},
  year           = {2022},
  place          = {Jedda Saudi Arabia},
  img            = {assets/img/projects/inr-gan.png},
  info           = {We introduce HyperCGAN, a conceptually simple approach for Adversarial Text to Continuous Image Generation that utilizes HyperNetworks to condition an Implicit Neural Representations (INR)-based GAN model on text.},
}

@InProceedings{shentsing,
  title          = {Knowledge-enhanced Medical Relation Extraction},
  group          = {Yongfeng Huang},
  org            = {Tsinghua University},
  year           = {2021},
  place          = {Beijing China},
  img            = {assets/img/projects/kemre.jpg},
  info           = {We propose a knowledge-enhanced framework for medical relation extraction (RE), which can exploit medical knowledge of medicines to better conduct medical RE on Chinese medicine instructions.}
}

@InProceedings{shenhebei,
  title          = {Self-Supervised Medical Image Segmentation},
  group          = {Zhenghua Xu},
  org            = {Hebei University of Technology and University of Oxford},
  year           = {2021},
  place          = {Tianjin China},
  img            = {assets/img/projects/medical.png},
  info           = {We proposes a multimodality contrastive self-supervised medical image segmentation method that utilizes a novel domain sharing generative adversarial network to achieve a contrastive domain translation.},
}