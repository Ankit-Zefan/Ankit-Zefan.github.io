---
---

@STRING{CVPR = {}}
@STRING{ECCV = {}}
@STRING{ICCV = {}}
@STRING{NEURIPS = {Advances in Neural Information Processing Systems (NeurIPS)}}
@STRING{Arxiv = {Arxiv}}

@inproceedings{Chen2023minigpt-v2,
  author    = {Chen, Jun and Zhu Deyao and Shen, Xiaoqian and Li, Xiang and Liu, Zechun and Zhang, Pengchuan and Krishnamoorthi, Raghuraman and Chandra, Vikas and Xiong, Yunyang and Elhoseiny, Mohamed},
  title     = {MiniGPT-v2: Large Language Model as a Unified Interface for Vision-Language Multi-task Learning},
  journal   = {Preprint},
  year      = {2023},
  pdf = {https://arxiv.org/abs/2310.09478},
  html = {https://minigpt-v2.github.io},
  code = {https://github.com/Vision-CAIR/MiniGPT-4},
  img  = {assets/img/publications/minigpt-v2.png},
}

@inproceedings{haydarov2023affect,
  author    = {Haydarov, Kilichbek and Shen, Xiaoqian and Madasu, Avinash and Salem, Mahmoud and Li, Li-Jia and Elsayed, Gamaleldin and Elhoseiny, Mohamed},
  title     = {Affective Visual Dialog: A Large-Scale Benchmark for Emotional Reasoning Based on Visually Grounded Conversations},
  journal   = {Arxiv preprint},
  year      = {2023},
  pdf = {https://arxiv.org/abs/2308.16349},
  html = {https://affective-visual-dialog.github.io},
  code = {https://github.com/Vision-CAIR/affectiveVisDial},
  img  = {assets/img/publications/dial.png},
}

@inproceedings{bakr2023hrsbench,
  author    = {Bakr, Eslam and Shen*, Xiaoqian and Sun*, Pengzhan and Khan*, Faizan and Li, Erran and Elhoseiny, Mohamed},
  title     = {HRS-Bench: Holistic, Reliable and Scalable Benchmark for Text-to-Image Models},
  journal   = {International Conference on Computer Vision (ICCV)},
  year      = {2023},
  pdf = {https://arxiv.org/abs/2304.05390},
  html = {https://eslambakr.github.io/hrsbench.github.io},
  code = {https://github.com/eslambakr/HRS_benchmark},
  img  = {assets/img/publications/hrs.png},
}


@inproceedings{shen2022mostgan,
  author    = {Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  title     = {MoStGAN-V: Video Generation with Temporal Motion Styles},
  journal   = {Computer Vision and Pattern Recognition Conference (CVPR)},
  year      = {2023},
  html = {https://xiaoqian-shen.github.io/MoStGAN-V},
  pdf = {https://arxiv.org/abs/2304.02777},
  code = {https://github.com/xiaoqian-shen/MoStGAN-V},
  img  = {assets/img/publications/mostgan.png},
}

@inproceedings{zhu2023MiniGPT-4,
  author    = {Zhu, Deyao and Jun, Chen and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  title     = {MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models},
  journal   = {Arxiv preprint},
  html = {https://minigpt-4.github.io},
  pdf = {https://arxiv.org/abs/2304.10592},
  code = {https://github.com/Vision-CAIR/MiniGPT-4},
  model = {https://huggingface.co/Vision-CAIR/MiniGPT-4},
  data = {https://huggingface.co/datasets/Vision-CAIR/cc_sbu_align},
  img  = {assets/img/publications/minigpt4.png},
  video = {https://www.youtube.com/watch?v=__tftoxpBAw}
}

@inproceedings{zhu2023chatcap,
  author    = {Zhu, Deyao and Jun, Chen and Haydarov, Kilichbek and Shen, Xiaoqian and Zhang, Wenxuan and Elhoseiny, Mohamed},
  title     = {ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions},
  journal   = {Arxiv preprint},
  pdf = {https://arxiv.org/abs/2303.06594},
  code = {https://github.com/Vision-CAIR/ChatCaptioner},
  img  = {assets/img/publications/chatcap.gif},
}

@ARTICLE{10167829,
  author={Zhang, Jiaojiao and Zhang, Shuo and Shen, Xiaoqian and Lukasiewicz, Thomas and Xu, Zhenghua},
  journal={IEEE Transactions on Medical Imaging},
  title={Multi-ConDoS: Multimodal Contrastive Domain Sharing Generative Adversarial Networks for Self-Supervised Medical Image Segmentation},
  year={2023},
  pdf = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10167829},
  img  = {assets/img/publications/condos.png}
 }


@inproceedings{yi2022exploring,
  author    = {Yi, Kai and Shen, Xiaoqian and Gou, Yunhao and Elhoseiny, Mohamed},
  title     = {Exploring hierarchical graph representation for large-scale zero-shot image classification},
  journal   = {European Conference on Computer Vision (ECCV),},
  year      = {2022},
  html = {https://kaiyi.me/p/hgrnet},
  pdf = {https://arxiv.org/pdf/2206.00665.pdf},
  supp = {https://drive.google.com/file/d/16MhTVGHCg20QB1_brETRls42QZBsD9eI/view},
  code = {https://github.com/WilliamYi96/hgr-net},
  img  = {assets/img/publications/hgr-net.png},
}

@misc{
haydarov2023adversarial,
title={Adversarial Text to Continuous Image Generation},
author={Kilichbek Haydarov and Aashiq Muhamed and Jovana Lazarevic and Ivan Skorokhodov and Xiaoqian Shen and Chamuditha Jayanga Galappaththige and Mohamed Elhoseiny},
journal = {OpenReview},
year      = {2022},
html = {https://hypercgan-web.s3.amazonaws.com/index.html},
code = {https://drive.google.com/file/d/1HDDlOll_0Vrd-y7vXj2-ph96jJkJ7K8t/view},
pdf={https://openreview.net/forum?id=9X3UZJSGIg9},
img = {assets/img/publications/inr-gan.png},
}

@article{qi2021kemre,
  title={KeMRE: knowledge-enhanced medical relation extraction for Chinese medicine instructions},
  author={Qi, Tao and Qiu, Shan and Shen, Xiaoqian and Chen, Haopu and Yang, Shuai and Wen, Hao and Zhang, Ya and Wu, Yuanqing and Huang, Yongfeng},
  journal={Journal of Biomedical Informatics},
  year={2021},
  volume={120},
  pages={103834},
  pdf = {https://www.sciencedirect.com/science/article/pii/S1532046421001623},
  img  = {assets/img/publications/kemre.jpg},
}