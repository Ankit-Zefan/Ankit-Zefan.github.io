
    <!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==" crossorigin="anonymous" referrerpolicy="no-referrer" />

  <title>Xiaoqian Shen</title>
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">
</head>

<body>
    <div class="container" style="margin-left: 15em;">
        <div class="row" style="margin-top: 3em;">
            <div class="col-md-11" style="margin-bottom: 1em;">
            <h3 class="display-4" style="text-align: center;"><span style="font-weight: bold;">Xiaoqian</span> Shen&emsp;沈晓倩</h3>
            </div>
            <br>
            <div class="col-md-8" style="">
                
                <p>
                <span style="font-weight: bold;">Bio:</span>
                I am currently a Master student of Computer Science at <a href="https://cemse.kaust.edu.sa/" target="_blank">King
                Abdullah University of Science and Technology</a> supervised by <a
                    href="https://cemse.kaust.edu.sa/people/person/mohamed-elhoseiny" target="_blank">Mohamed
                Elhoseiny</a>.
                Before that, I received BSc in Computer Science from <a href="https://global.jlu.edu.cn/"
                                                                        target="_blank">Jilin University</a>, China.
            </p>
            <p>
                <span style="font-weight: bold;">Research:</span>
                I am excited about complex problems that can be tackled with learning-based systems. Currently, my
                research focuses on generative models, spatiotemporal representation and low-resource learning.
            <p>
            <span style="font-family: Monaco, monospace;">Feel free to reach out to me:</span>  <span style="font-weight: bold;"><a style="color: black;" href="mailto:xiaoqian.shen@kaust.edu.sa">xiaoqian.shen@kaust.edu.sa</a></span></p> 
            </p>
            <p>
                <a href="assets/pdf/resume.pdf" target="_blank"
                   style="margin-right: 15px"><i class="fa fa-address-card fa-lg"></i> Resume</a>
                <a href="https://twitter.com/xiaoqian_shen" target="_blank" style="margin-right: 15px"><i
                        class="fab fa-twitter fa-lg"></i> Twitter</a>
                <a href="https://scholar.google.com/citations?hl=en&user=uToGtIwAAAAJ" target="_blank"
                   style="margin-right: 15px"><i class="fa-solid fa-book"></i> Scholar</a>
                <a href="https://github.com/xiaoqian-shen" target="_blank" style="margin-right: 15px"><i
                        class="fab fa-github fa-lg"></i> Github</a>
                <a href="https://www.linkedin.com/in/xiaoqian-shen-759991264/" target="_blank"
                   style="margin-right: 15px"><i class="fab fa-linkedin fa-lg"></i> LinkedIn</a>
            </p>
    
            </div>
            <div class="col-md-4" style="">
                <img src="assets/img/profile.jpg" class="img-thumbnail" width="240px" alt="Profile picture">
            </div>
        </div>
        
        <h3>News</h3>
        <table width="100%" align="center" border="0" cellspacing="0">
          <tr>
            <td width="60%" valign="middle">
              <ul>
                <li> <b>2023-07</b> One paper (HRS-Bench) gets accepted to ICCV'23 </li>
                <li> <b>2023-04</b> We released MiniGPT-4 and received github 10k stars in 3 days </li>
                <li> <b>2023-02</b> One paper (MoStGAN-V) gets accepted to CVPR'23 </li>
                <li> <b>2022-09</b> Start my Master jounery in King Abdullah University of Science and Technology (KAUST) </li>
                <li> <b>2022-07</b> One paper gets accepted to ECCV'22 </li>
                <li> <b>2021-12</b> Join Vision-CAIR at King Abdullah University of Science and Technology as a visiting research student</li>
              </ul>
            </td>
          </tr>
        </table>
        
        <div class="row" style="margin-top: 1em;">
            <div class="col-md-10" style="">
                <h3>Publications</h3>
                <br>
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-4"><img src="assets/img/publications/hrs.png" border="0" class="img-fluid" width="300" height="60" alt="Project image"></div><div class="col-sm-8"><span style= "font-weight: bold;font-size: 18px;font-family: normal;">HRS-Bench: Holistic, Reliable and Scalable Benchmark for Text-to-Image Models</span> <br>Eslam Bakr, <span style="font-weight: bold";>Xiaoqian Shen*</span>, Pengzhan Sun*, Faizan Khan, Erran Li, Mohamed Elhoseiny <br><span style="font-style: italic;">International Conference on Computer Vision (ICCV), 2023 </span> <br><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://eslambakr.github.io/hrsbench.github.io" target="_blank">Project Page</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2304.05390" target="_blank">Paper</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/eslambakr/HRS_benchmark" target="_blank">Code</a> </div> </div> <hr> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-4"><img src="assets/img/publications/mostgan.png" border="0" class="img-fluid" width="300" height="60" alt="Project image"></div><div class="col-sm-8"><span style= "font-weight: bold;font-size: 18px;font-family: normal;">MoStGAN-V: Video Generation with Temporal Motion Styles</span> <br><span style="font-weight: bold";>Xiaoqian Shen</span>, Xiang Li, Mohamed Elhoseiny <br><span style="font-style: italic;">Computer Vision and Pattern Recognition Conference (CVPR), 2023 </span> <br><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://xiaoqian-shen.github.io/MoStGAN-V" target="_blank">Project Page</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2304.02777" target="_blank">Paper</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/xiaoqian-shen/MoStGAN-V" target="_blank">Code</a> </div> </div> <hr> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-4"><img src="assets/img/publications/minigpt4.png" border="0" class="img-fluid" width="300" height="60" alt="Project image"></div><div class="col-sm-8"><span style= "font-weight: bold;font-size: 18px;font-family: normal;">MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models</span> <br>Deyao Zhu, Chen Jun, <span style="font-weight: bold";>Xiaoqian Shen</span>, Xiang Li, Mohamed Elhoseiny <br><span style="font-style: italic;">Arxiv preprint  </span> <br><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://minigpt-4.github.io" target="_blank">Project Page</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2304.10592" target="_blank">Paper</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/Vision-CAIR/MiniGPT-4" target="_blank">Code</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.youtube.com/watch?v=__tftoxpBAw" target="_blank">Video</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://huggingface.co/Vision-CAIR/MiniGPT-4" target="_blank">Model</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://huggingface.co/datasets/Vision-CAIR/cc_sbu_align" target="_blank">Dataset</a> </div> </div> <hr> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-4"><img src="assets/img/publications/chatcap.gif" border="0" class="img-fluid" width="300" height="60" alt="Project image"></div><div class="col-sm-8"><span style= "font-weight: bold;font-size: 18px;font-family: normal;">ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions</span> <br>Deyao Zhu, Chen Jun, Kilichbek Haydarov, <span style="font-weight: bold";>Xiaoqian Shen</span>, Wenxuan Zhang, Mohamed Elhoseiny <br><span style="font-style: italic;">Arxiv preprint  </span> <br><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2303.06594" target="_blank">Paper</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/Vision-CAIR/ChatCaptioner" target="_blank">Code</a> </div> </div> <hr> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-4"><img src="assets/img/publications/condos.png" border="0" class="img-fluid" width="300" height="60" alt="Project image"></div><div class="col-sm-8"><span style= "font-weight: bold;font-size: 18px;font-family: normal;">Multi-ConDoS: Multimodal Contrastive Domain Sharing Generative Adversarial Networks for Self-Supervised Medical Image Segmentation</span> <br>Jiaojiao Zhang, Shuo Zhang, <span style="font-weight: bold";>Xiaoqian Shen</span>, Thomas Lukasiewicz, Zhenghua Xu <br><span style="font-style: italic;">IEEE Transactions on Medical Imaging 2023 </span> <br><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10167829" target="_blank">Paper</a> </div> </div> <hr> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-4"><img src="assets/img/publications/hgr-net.png" border="0" class="img-fluid" width="300" height="60" alt="Project image"></div><div class="col-sm-8"><span style= "font-weight: bold;font-size: 18px;font-family: normal;">Exploring hierarchical graph representation for large-scale zero-shot image classification</span> <br>Kai Yi, <span style="font-weight: bold";>Xiaoqian Shen</span>, Yunhao Gou, Mohamed Elhoseiny <br><span style="font-style: italic;">European Conference on Computer Vision (ECCV), 2022 </span> <br><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://kaiyi.me/p/hgrnet" target="_blank">Project Page</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2206.00665.pdf" target="_blank">Paper</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://drive.google.com/file/d/16MhTVGHCg20QB1_brETRls42QZBsD9eI/view" target="_blank">Supplementary</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/WilliamYi96/hgr-net" target="_blank">Code</a> </div> </div> <hr> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-4"><img src="assets/img/publications/inr-gan.png" border="0" class="img-fluid" width="300" height="60" alt="Project image"></div><div class="col-sm-8"><span style= "font-weight: bold;font-size: 18px;font-family: normal;">Adversarial Text to Continuous Image Generation</span> <br>Kilichbek Haydarov, Aashiq Muhamed, Jovana Lazarevic, Ivan Skorokhodov, <span style="font-weight: bold";>Xiaoqian Shen</span>, Chamuditha Galappaththige, Mohamed Elhoseiny <br><span style="font-style: italic;">OpenReview 2022 </span> <br><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://hypercgan-web.s3.amazonaws.com/index.html" target="_blank">Project Page</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://openreview.net/forum?id=9X3UZJSGIg9" target="_blank">Paper</a> <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://drive.google.com/file/d/1HDDlOll_0Vrd-y7vXj2-ph96jJkJ7K8t/view" target="_blank">Code</a> </div> </div> <hr> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-4"><img src="assets/img/publications/kemre.jpg" border="0" class="img-fluid" width="300" height="60" alt="Project image"></div><div class="col-sm-8"><span style= "font-weight: bold;font-size: 18px;font-family: normal;">KeMRE: knowledge-enhanced medical relation extraction for Chinese medicine instructions</span> <br>Tao Qi, Shan Qiu, <span style="font-weight: bold";>Xiaoqian Shen</span>, Haopu Chen, Shuai Yang, Hao Wen, Ya Zhang, Yuanqing Wu, Yongfeng Huang <br><span style="font-style: italic;">Journal of Biomedical Informatics 2021 </span> <br><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.sciencedirect.com/science/article/pii/S1532046421001623" target="_blank">Paper</a> </div> </div> <hr> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-4"><img src="assets/img/publications/splice.png" border="0" class="img-fluid" width="300" height="60" alt="Project image"></div><div class="col-sm-8"><span style= "font-weight: bold;font-size: 18px;font-family: normal;">Image Splicing Location Based on Illumination Maps and Cluster Region Proposal Network</span> <br>Ye Zhu, <span style="font-weight: bold";>Xiaoqian Shen</span>, Shikun Liu, Xiaoli Zhang, Gang Yan <br><span style="font-style: italic;">Applied Sciences 2021 </span> <br><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.mdpi.com/2076-3417/11/18/8437" target="_blank">Paper</a> </div> </div> <hr> </div>
            </div>
        </div>
        <div class="row" style="margin-top: 1em;">
            <div class="col-md-10" style="">
                <h3>Projects</h3>
                <br>
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-4"><img src="assets/img/projects/dial.png" class="img-fluid" alt="Project image"></div><div class="col-sm-8"><span style= "font-weight: bold;font-size: 18px;font-family: normal;">Affective Visual Dialog</span><br>Mohamed Elhoseiny,   <span style="color: blue;">Vision-CAIR KAUST</span>,  Jedda Saudi Arabia, 2022 <br>&emsp;&emsp;<span style="font-family: Verdana;">We study the role of affective language in the form of conversation grounded on visual stimuli in informing human emotion and collect a new dataset for (1) Dialog-based Question Answering; (2) Dialog-based Emotion classification and Affective explanation.</span><br> </div> </div> <hr> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-4"><img src="assets/img/projects/inr-gan.png" class="img-fluid" alt="Project image"></div><div class="col-sm-8"><span style= "font-weight: bold;font-size: 18px;font-family: normal;">Adversarial Text to Continuous Image Generation</span><br>Mohamed Elhoseiny,   <span style="color: blue;">Vision-CAIR KAUST</span>,  Jedda Saudi Arabia, 2022 <br>&emsp;&emsp;<span style="font-family: Verdana;">We introduce HyperCGAN, a conceptually simple approach for Adversarial Text to Continuous Image Generation that utilizes HyperNetworks to condition an Implicit Neural Representations (INR)-based GAN model on text.</span><br> </div> </div> <hr> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-4"><img src="assets/img/projects/kemre.jpg" class="img-fluid" alt="Project image"></div><div class="col-sm-8"><span style= "font-weight: bold;font-size: 18px;font-family: normal;">Knowledge-enhanced Medical Relation Extraction</span><br>Yongfeng Huang,   <span style="color: blue;">Tsinghua University</span>,  Beijing China, 2021 <br>&emsp;&emsp;<span style="font-family: Verdana;">We propose a knowledge-enhanced framework for medical relation extraction (RE), which can exploit medical knowledge of medicines to better conduct medical RE on Chinese medicine instructions.</span><br> </div> </div> <hr> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-4"><img src="assets/img/projects/medical.png" class="img-fluid" alt="Project image"></div><div class="col-sm-8"><span style= "font-weight: bold;font-size: 18px;font-family: normal;">Self-Supervised Medical Image Segmentation</span><br>Zhenghua Xu,   <span style="color: blue;">Hebei University of Technology and University of Oxford</span>,  Tianjin China, 2021 <br>&emsp;&emsp;<span style="font-family: Verdana;">We proposes a multimodality contrastive self-supervised medical image segmentation method that utilizes a novel domain sharing generative adversarial network to achieve a contrastive domain translation.</span><br> </div> </div> <hr> </div>
            </div>
        </div>
        <!-- <div class="row" style="margin-top: 3em; margin-bottom: 1em;">
            
            <div class="col-sm-12" style="">
                <h4>Homepage Template</h4>
                <p>
                    Feel free to use this website as a template! It is fully responsive and very easy to use and maintain as it uses a python script that crawls your bib files to automatically add the papers and talks. If you find it helpful, please add a link to my website - I will also add a link to yours (if you want). <a href="https://github.com/m-niemeyer/m-niemeyer.github.io" target="_blank">Checkout the github repository for instructions on how to use it</a>. <br>
                    <a href="https://kashyap7x.github.io/" target="_blank">&#9883;</a>
                    <a href="https://kait0.github.io/" target="_blank">&#9883;</a>
                </p>
            </div>
     
        </div> -->
    </div>
    
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
      integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
      crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
      integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
      crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
      integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
      crossorigin="anonymous"></script>
</body>

</html>
    